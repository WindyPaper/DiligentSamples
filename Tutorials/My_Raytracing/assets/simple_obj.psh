#include "simple_obj_common.csh"

Texture3D    g_Texture;
SamplerState g_Texture_sampler; // By convention, texture samplers must use the '_sampler' suffix

Texture2D g_NoiseTex;
SamplerState g_NoiseTex_sampler;

struct PSInput 
{ 
    float4 Pos   : SV_POSITION; 
    float2 UV : TEX_COORD; 
    float4 PixelWPos : TEX_COORD1;
    float3 WNormal : TEX_COORD2;
    float3 PixelViewPos : TEX_COORD3;
    float4 ClipPos : TEX_COORD4;

};

struct PSOutput
{ 
    float4 Color : SV_TARGET; 
    float depth : SV_Depth;
};

static const float pi = 3.141592;
static const float2 hexRatio = float2(1.0, sqrt(3.0));

//credits for hex tiling goes to Shane (https://www.shadertoy.com/view/Xljczw)
//center, index
float4 GetHexGridInfo(float2 uv)
{
  float4 hexIndex = round(float4(uv, uv - float2(0.5, 1.0)) / hexRatio.xyxy);
  float4 hexCenter = float4(hexIndex.xy * hexRatio, (hexIndex.zw + 0.5) * hexRatio);
  float4 offset = uv.xyxy - hexCenter;
  return dot(offset.xy, offset.xy) < dot(offset.zw, offset.zw) ? 
    float4(hexCenter.xy, hexIndex.xy) : 
    float4(hexCenter.zw, hexIndex.zw);
}

float GetHexSDF(in float2 p)
{
  p = abs(p);
  return 0.5 - max(dot(p, hexRatio * 0.5), p.x);
}

//xy: node pos, z: weight
float3 GetTriangleInterpNode(in float2 pos, in float freq, in int nodeIndex)
{
  float2 nodeOffsets[3] = {
    float2(0.0, 0.0),
    float2(1.0, 1.0),
    float2(1.0,-1.0)};

  float2 uv = pos * freq + nodeOffsets[nodeIndex] / hexRatio.xy * 0.5;
  float4 hexInfo = GetHexGridInfo(uv);
  float dist = GetHexSDF(uv - hexInfo.xy) * 2.0;
  return float3(hexInfo.xy / freq, dist);
}

float3 hash33( float3 p )
{
	p = float3( dot(p,float3(127.1,311.7, 74.7)),
			  dot(p,float3(269.5,183.3,246.1)),
			  dot(p,float3(113.5,271.9,124.6)));

	return frac(sin(p)*43758.5453123);
}

float2 GetTextureSampleUV(float2 pos, float freq, float2 nodePoint)
{
    float3 hash = hash33(float3(nodePoint.xy, 0));
    float ang = hash.x * 2.0 * pi;
    float2x2 rotation = {cos(ang), sin(ang), -sin(ang), cos(ang)};
    
    //float2 rot_pos = mul(pos, rotation);
    float2 rot_pos = mul(rotation, pos);
    float2 uv = rot_pos * freq + hash.yz;
    //return texture(iChannel0, uv);
    return uv;
}

//from Qizhi Yu, et al [2011]. Lagrangian Texture Advection: Preserving Both Spectrum and Velocity Field. 
//IEEE Transactions on Visualization and Computer Graphics 17, 11 (2011), 1612â€“1623
float3 PreserveVariance(float3 linearColor, float3 meanColor, float moment2)
{
    return (linearColor - meanColor) / sqrt(moment2) + meanColor;
}

// Rotation with angle (in radians) and axis
float3x3 AngleAxis3x3(float angle, float3 axis)
{
    float c, s;
    sincos(angle, s, c);

    float t = 1 - c;
    float x = axis.x;
    float y = axis.y;
    float z = axis.z;

    return float3x3(
        t * x * x + c,      t * x * y - s * z,  t * x * z + s * y,
        t * x * y + s * z,  t * y * y + c,      t * y * z - s * x,
        t * x * z - s * y,  t * y * z + s * x,  t * z * z + c
    );
}

struct RaycastResult
{
    float3 world_normal;
    float2 uv;
    float3 world_pos;
    float4 color;
};
RaycastResult RaycastFur(float3 world_pos, float3 world_dir, float2 uv, float3x3 world_to_uv, float3x3 uv_to_fur, float density_bias)
{
    float3x3 fur_to_uv = (Inverse3x3(uv_to_fur));
    
    float3 uv_ray_dir = mul(world_dir, world_to_uv);
    
    float3 fur_ray_start = mul(float3(uv, 0.0f), uv_to_fur);
    float3 fur_ray_dir = mul(uv_ray_dir, uv_to_fur);
    //fur_ray_dir.xy += normalize(fur_ray_dir.xy) * 0.01f;
    
    float fur_ray_length = length((fur_ray_dir).xy );
    float2 fur_planar_dir = normalize(fur_ray_dir.xy);
    float ang = atan2(fur_planar_dir.y, fur_planar_dir.x);
    
    float2 fur_planar_perp = float2(-fur_planar_dir.y, fur_planar_dir.x);
    
    float3 lookup_coord = float3(fur_ray_start.xy, ang / (2.0f * 3.1415f));
    
    float p = 5.0f;
    float mult = 1.0f;
    
    float4 tex_sample = g_Texture.SampleLevel(g_Texture_sampler, lookup_coord, 0.0f); //tex3Dlod(precomputed_tex, precomputed_tex_sampler, float4(lookup_coord, 0.0f));
    

    float hit_dist = 1.0f / (tex_sample.r + 1e-7f) - 1.0f;
    //float hit_dist = tex_sample.r;
    float3 fur_hit_normal;

    fur_hit_normal.xyz = tex_sample.gba * 2.0f - 1.0f;
    fur_hit_normal.z *= -1.0f;
    
    
    float angle_ratio = density_bias * 1000.0f; 
    //fur_hit_normal.z = angle_ratio;
    //fur_hit_normal = normalize(fur_hit_normal);
    
    float dist_scale = hit_dist * 100.0f * BakeHeightScale / (length(fur_ray_dir.xy) + abs(normalize(fur_ray_dir).z) * angle_ratio + 0.01f * 0.0f);
    float uv_dist_scale = hit_dist / length(fur_ray_dir.xy);

    float3x3 fur_to_uv_normal = fur_to_uv;
    /*fur_to_uv_normal[0] = normalize(fur_to_uv_normal[0]);
    fur_to_uv_normal[1] = normalize(fur_to_uv_normal[1]);
    fur_to_uv_normal[2] = normalize(fur_to_uv_normal[2]);*/
    
    float3 uv_hit_normal = mul(fur_hit_normal, transpose(uv_to_fur) );
    
    RaycastResult res;
    res.world_normal = normalize(mul(uv_hit_normal, transpose(world_to_uv) )); //this is how normals are transformed
    res.world_pos = world_pos + world_dir * dist_scale;
    res.uv = uv + uv_ray_dir.xy * uv_dist_scale;
    
    return res;
}

float4x4 GetViewProjectionTransform()
{
    return g_WorldViewProj;
}

float3 Project(in float3 world_point, in float4x4 proj_matrix)
{
	float4 world_point4;
	world_point4.xyz = world_point;
	world_point4.w = 1.0f;
	float4 normalized_pos = mul(world_point4, proj_matrix);
	normalized_pos /= normalized_pos.w;
	float2 screen_point = normalized_pos.xy * 0.5f + float2(0.5f, 0.5f);
	screen_point.y = 1.0f - screen_point.y;
	return float3(screen_point.xy, normalized_pos.z);
}

float4x4 GetViewProjectionTransformInv() 
{
    return g_ViewProjMatInv;
}

float3 GetWorldPoint(float2 screenspace_point, float nonlinear_depth)
{
    float4 projected_pos;
    projected_pos.x = screenspace_point.x * 2.f - 1.f;
    projected_pos.y = ( 1.f - screenspace_point.y ) * 2.f - 1.f;
    projected_pos.z = nonlinear_depth;
    projected_pos.w = 1.f;
    float4 world_pos = mul( projected_pos, GetViewProjectionTransformInv() );
    world_pos /= world_pos.w;
    return world_pos.xyz;
}

// Note that if separate shader objects are not supported (this is only the case for old GLES3.0 devices), vertex
// shader output variable name must match exactly the name of the pixel shader input variable.
// If the variable has structure type (like in this example), the structure declarations must also be indentical.
void main(in  PSInput  PSIn,
          out PSOutput PSOut)
{
    float WindSpeed = 0.0016f;
    float WindStrength = 0.14f;
    float FlowUVSpeed = Time % 1024 * WindSpeed;
    float2 FlowUV0 = (PSIn.UV + float2(FlowUVSpeed, FlowUVSpeed)) * FlowUVTexTiling;

    float plane_w = bbox_max.x - bbox_min.x;
    float plane_h = bbox_max.z - bbox_min.z;

    //float2 flow_dir = float2(0.5f, 0.5f);
    float3 flow_data = g_NoiseTex.Sample(g_NoiseTex_sampler, PSIn.UV * BakeTexTiling).rgb;
    float2 flow_dir = flow_data.xy * 2.0f - 1.0f;

    float3 b_flow_data = g_NoiseTex.Sample(g_NoiseTex_sampler, FlowUV0).rgb;
    float2 b_flow_dir = b_flow_data.xy * 2.0f - 1.0f;
    float2 in_uv = PSIn.UV * BakeTexUVTiling + (0.00024f * BakeTexUVFlowIntensity * b_flow_dir);

    flow_dir *= FlowIntensity;


	float3 world_ray_origin = PSIn.PixelWPos.xyz;  
	float2 screen_ray_origin = Project(world_ray_origin, GetViewProjectionTransform()).xy;
	float3 world_ray_dir = normalize(GetWorldPoint(screen_ray_origin, 1.0f) - GetWorldPoint(screen_ray_origin, 0.0f));
	
	//out_world_pos = in_world_pos;
	//out_uv = in_uv;
	
    float3x3 tbn_basis;
    tbn_basis[0] = float3(1.0f, 0.0f, 0.0f);
    tbn_basis[1] = float3(0.0f, 1.0f, 0.0f);
    tbn_basis[2] = float3(0.0f, 0.0f, 1.0f);
    
	float3 fiber_world_dir = normalize(tbn_basis[1] + normalize(tbn_basis[0]) * flow_dir.x + normalize(tbn_basis[2]) * flow_dir.y);
	//float gravity = Gravity;
	fiber_world_dir = normalize(fiber_world_dir + float3(0.0f, -0.5f, 0.0f) * 0.0f);
    float test_temp_val = 2.0f * Gravity;
	
	float3x3 uv_to_world;
	uv_to_world[0] = tbn_basis[0];
	uv_to_world[2] = tbn_basis[2];
	uv_to_world[1] = fiber_world_dir * length(tbn_basis[0]);	
	//uv_to_world = uv_to_world;
	
    float freq_mult = FreqMult;
	float3x3 uv_to_fur_0;
	{
		float rotation_ang = 0.1f + 0.3f;//3.14 / 2.0f;
		float2 planar_dir = float2(cos(rotation_ang), sin(rotation_ang));
        //float2 planar_dir = float2(1.0f, 0.0f);
		float3 basis_dir0 = float3( planar_dir.x, planar_dir.y, 0.0f);
		float3 basis_dir1 = float3(-planar_dir.y, planar_dir.x, 0.0f);
		float3 basis_dir2 = float3(0.0f, 0.0f, 1.0f);
		
		uv_to_fur_0 = float3x3(basis_dir0, basis_dir1, basis_dir2) * freq_mult;	
	}

    float3x3 uv_to_fur_1;
	{
		float rotation_ang = 3.1415f * 1.61f + 0.9f;
		float2 planar_dir = float2(cos(rotation_ang), sin(rotation_ang));
        //float2 planar_dir = float2(1.0f, 0.0f);
		float3 basis_dir0 = float3( planar_dir.x, planar_dir.y, 0.0f);
		float3 basis_dir1 = float3(-planar_dir.y, planar_dir.x, 0.0f);
		float3 basis_dir2 = float3(0.0f, 0.0f, 1.0f);
		
		uv_to_fur_1 = float3x3(basis_dir0, basis_dir1, basis_dir2) * freq_mult * 1.16f;	
	}

    float density_bias = DensityBias;
    //float2 in_uv = PSIn.UV;
    float3x3 world_to_uv = (Inverse3x3(uv_to_world));
    RaycastResult raycast_res0 = RaycastFur(world_ray_origin, world_ray_dir, in_uv, world_to_uv, uv_to_fur_0, density_bias);
    RaycastResult raycast_res1 = RaycastFur(world_ray_origin, world_ray_dir, in_uv, world_to_uv, uv_to_fur_1, density_bias);

    bool choose_0 = dot(raycast_res0.world_pos - world_ray_origin, world_ray_dir) < dot(raycast_res1.world_pos - world_ray_origin, world_ray_dir);
	float3 out_world_pos = choose_0 ? raycast_res0.world_pos : raycast_res1.world_pos;
	float3 out_world_normal = choose_0 ? raycast_res0.world_normal : raycast_res1.world_normal;

    //lighting 
    float3 test_dir_light = normalize(float3(0.5f, 0.5f, 0.5f));
    float ndotl = saturate(dot(test_dir_light, out_world_normal));
    float3 dir_lighting = ndotl * float3(1.0f, 1.0f, 1.0f);
    //float3 dir_lighting = saturate(bake_data.rgb) * float3(1.0f, 1.0f, 1.0f);
    //PSOut.Color = float4(abs(new_depth - PSIn.PixelWPos.z)) + 0.00000001f * float4(dir_lighting, 1.0f);

    float3 surface_norm = -normalize(tbn_basis[1]);
	float fiber_depth = dot(out_world_pos - world_ray_origin, surface_norm);

	float cosa = -dot(surface_norm, fiber_world_dir.xyz);
	//fiber_coord = fiber_depth / cosa;
	float fiber_density_scale = 1.0f / cosa;
    float attenuation_depth = AttenuationDepth;
	float attenuation = exp(-fiber_depth * fiber_density_scale / attenuation_depth);    

    float3 GrassColor = float3(0.05f, 0.2f, 0.05f);
    float3 subsurface_light = 
				lerp(saturate(1.0f - ndotl), 1.0f, 1.0f) *
				saturate( (ndotl + 0.5f) / (1.0f + 0.5f) ) * GrassColor / 2.0f;

    
    //float DepthColorGradient = 0.36f;
    float3 subsurface_color = lerp(1.0f, attenuation, DepthColorGradient) * flow_data;

    float4 ndc_pos = PSIn.ClipPos;
    ndc_pos.xyz /= ndc_pos.w;
    // ndc_pos.xyz *= PSIn.PixelViewPos.z;
    // float4 cal_view_pos = mul(ndc_pos, inverse4x4(g_ProjMat));
    // cal_view_pos.xyz /= cal_view_pos.w;

    //float reverse_z = g_ProjMat[3].z / ()
    float4x4 transpose_proj_mat = g_ProjMat;
    // float z_eye = transpose_proj_mat[3].z/(-ndc_pos.z - transpose_proj_mat[2].z);
    // float z_eye = g_ProjMat[2].w/(ndc_pos.z - g_ProjMat[2].z);
    float z_eye = g_ProjMat[3].z/(ndc_pos.z - g_ProjMat[2].z);
    // float z_eye = -0.1f/(ndc_pos.z - 1.0f);

    //float3 offset_v = abs(PSIn.PixelViewPos.xyz - cal_view_pos.xyz);
    float offset_eyez = abs(PSIn.PixelViewPos.z - z_eye);
    float3 offset_v = float3(offset_eyez, offset_eyez, offset_eyez);

    PSOut.Color = attenuation * float4(dir_lighting * GrassColor + subsurface_light + subsurface_color, 1.0f) * float4(offset_v, 1.0f);   
    //PSOut.Color = float4(attenuation, attenuation, attenuation, 1.0f);

    PSOut.depth = Project(out_world_pos, GetViewProjectionTransform()).z;

    //PSOut.OutDepth = g_Texture.Sample(g_Texture_sampler, float3)
}
